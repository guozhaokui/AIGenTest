# å­¦ä¹ æœºåˆ¶è®¾è®¡

## å­¦ä¹ æ¨¡å¼æ¦‚è§ˆ

ç³»ç»Ÿæ”¯æŒä¸‰ç§å­¦ä¹ æ¨¡å¼ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ‰¹é‡å­¦ä¹ ï¼ˆBootstrap Learningï¼‰                   â”‚
â”‚  åˆå§‹åŒ–æ—¶æ‰«ææ‰€æœ‰å†å²æ–‡æ¡£ï¼Œå»ºç«‹åŸºç¡€çŸ¥è¯†åº“         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¢é‡å­¦ä¹ ï¼ˆIncremental Learningï¼‰                 â”‚
â”‚  ç›‘å¬æ–‡æ¡£å˜æ›´ï¼Œè‡ªåŠ¨æ›´æ–°çŸ¥è¯†åº“                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  äº¤äº’å­¦ä¹ ï¼ˆInteractive Learningï¼‰                 â”‚
â”‚  ä»å¯¹è¯ä¸­å­¦ä¹ ï¼Œä¸»åŠ¨ç¡®è®¤å’Œçº æ­£                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ‰¹é‡å­¦ä¹ ï¼ˆBootstrapï¼‰

### åˆå§‹åŒ–æµç¨‹

```python
class BootstrapLearner:
    def bootstrap(self, docs_path: str):
        """æ‰«ææ–‡æ¡£ç›®å½•ï¼Œå»ºç«‹åˆå§‹çŸ¥è¯†åº“"""

        # 1. æ‰«ææ‰€æœ‰æ–‡æ¡£
        documents = self.scan_documents(docs_path)
        print(f"å‘ç° {len(documents)} ä¸ªæ–‡æ¡£")

        # 2. é€ä¸ªå¤„ç†
        for doc in documents:
            self.process_document(doc)

        # 3. åå¤„ç†ï¼šåˆå¹¶ã€å»é‡ã€è®¡ç®—ç½®ä¿¡åº¦
        self.post_process()

        # 4. ç”Ÿæˆå¾…ç¡®è®¤åˆ—è¡¨
        uncertainties = self.identify_uncertainties()

        return {
            "total_entities": len(self.entities),
            "high_confidence": len([e for e in self.entities if e.confidence > 0.7]),
            "need_confirmation": uncertainties
        }

    def process_document(self, doc: Document):
        """å¤„ç†å•ä¸ªæ–‡æ¡£"""

        # 1. æå–å®ä½“
        entities = self.entity_extractor.extract(doc.content)

        # 2. ä¸ºæ¯ä¸ªå®ä½“æ¨æ–­å±æ€§
        for entity in entities:
            properties = self.infer_properties(entity, doc)
            relations = self.infer_relations(entity, doc, entities)

            # 3. å­˜å…¥çŸ¥è¯†åº“ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™åˆå¹¶ï¼‰
            self.knowledge_base.merge(
                entity=entity,
                properties=properties,
                relations=relations,
                source=doc.path
            )
```

### å®ä½“æå–ç­–ç•¥

#### ç­–ç•¥1ï¼šåŸºäºè§„åˆ™çš„æå–

```python
class RuleBasedExtractor:
    """åŸºäºå›ºå®šè§„åˆ™çš„å®ä½“æå–"""

    def __init__(self):
        # é¢„å®šä¹‰çš„å®ä½“è¯è¡¨
        self.known_entities = {
            "servers": ["linux81", "linux21", "usaæœåŠ¡å™¨", "usa-vps"],
            "projects": ["QAMath", "MetaGPT", "Claude Code", "DINOv3"],
            "environments": ["qwen", "hidream", "sam3d", "base"],
        }

    def extract(self, text: str) -> List[Entity]:
        entities = []

        # ç²¾ç¡®åŒ¹é…
        for category, names in self.known_entities.items():
            for name in names:
                if name in text:
                    entities.append(Entity(
                        name=name,
                        type=category.rstrip('s'),  # servers -> server
                        confidence=0.9,  # é«˜ç½®ä¿¡åº¦
                        extraction_method="rule_based"
                    ))

        return entities
```

#### ç­–ç•¥2ï¼šåŸºäºæ¨¡å¼çš„æå–

```python
class PatternExtractor:
    """åŸºäºæ­£åˆ™æ¨¡å¼çš„å®ä½“æå–"""

    PATTERNS = {
        "server": [
            r"(\w+)\s*æœåŠ¡å™¨",          # "xxxæœåŠ¡å™¨"
            r"linux(\d+)",             # "linux81"
            r"(\w+)-vps",              # "usa-vps"
        ],
        "conda_env": [
            r"\((\w+)\)",              # "(qwen)"
        ],
        "port": [
            r"(?:ç«¯å£|port)[:ï¼š]?\s*(\d{4,5})",  # "ç«¯å£: 6020"
            r"localhost:(\d{4,5})",    # "localhost:8000"
        ],
        "directory": [
            r"(~/[\w/]+)",             # "~/work/MetaGPT"
            r"(/[\w/]+)",              # "/mnt/hdd/guo/..."
        ],
        "command": [
            r"(?:python|bash|sh)\s+([\w/.]+)", # "python start.py"
        ]
    }

    def extract(self, text: str) -> List[Entity]:
        entities = []

        for entity_type, patterns in self.PATTERNS.items():
            for pattern in patterns:
                matches = re.findall(pattern, text)
                for match in matches:
                    entities.append(Entity(
                        name=match,
                        type=entity_type,
                        confidence=0.6,  # ä¸­ç­‰ç½®ä¿¡åº¦
                        extraction_method="pattern_based"
                    ))

        return entities
```

#### ç­–ç•¥3ï¼šåŸºäºLLMçš„æå–ï¼ˆå¯é€‰ï¼‰

```python
class LLMExtractor:
    """ä½¿ç”¨LLMæ™ºèƒ½æå–å®ä½“"""

    EXTRACTION_PROMPT = """
    ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®å®ä½“ï¼ˆæœåŠ¡å™¨ã€é¡¹ç›®ã€å·¥å…·ã€ç¯å¢ƒç­‰ï¼‰:

    {text}

    è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼š
    {{
        "entities": [
            {{"name": "...", "type": "server|project|tool|environment|other", "context": "..."}}
        ]
    }}
    """

    def extract(self, text: str) -> List[Entity]:
        response = self.llm.generate(
            self.EXTRACTION_PROMPT.format(text=text)
        )

        result = json.loads(response)
        entities = []

        for e in result["entities"]:
            entities.append(Entity(
                name=e["name"],
                type=e["type"],
                confidence=0.7,  # LLMæå–ç½®ä¿¡åº¦
                extraction_method="llm_based",
                context=e.get("context")
            ))

        return entities
```

### å±æ€§æ¨æ–­

```python
class PropertyInferrer:
    """æ¨æ–­å®ä½“çš„å±æ€§"""

    def infer_properties(self, entity: Entity, doc: Document) -> List[Property]:
        properties = []

        # 1. åŸºäºä¸Šä¸‹æ–‡æ¨æ–­
        context = self.get_context_window(entity, doc)

        # 2. æ ¹æ®å®ä½“ç±»å‹ä½¿ç”¨ä¸åŒçš„æ¨æ–­ç­–ç•¥
        if entity.type == "server":
            properties.extend(self.infer_server_properties(entity, context))
        elif entity.type == "project":
            properties.extend(self.infer_project_properties(entity, context))
        # ... å…¶ä»–ç±»å‹

        return properties

    def infer_server_properties(self, entity: Entity, context: str) -> List[Property]:
        properties = []

        # æ¨æ–­IPåœ°å€
        ip_pattern = r'\b\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\b'
        if match := re.search(ip_pattern, context):
            properties.append(Property(
                key="ip",
                value=match.group(),
                confidence=0.8
            ))

        # æ¨æ–­é…ç½®ä¿¡æ¯
        config_patterns = [
            r'(\d+)æ ¸',          # CPUæ ¸å¿ƒæ•°
            r'(\d+)G[B]?',       # å†…å­˜
            r'(\d+)å¡(\w+)',     # GPU
        ]
        for pattern in config_patterns:
            if match := re.search(pattern, context):
                properties.append(Property(
                    key="config",
                    value=match.group(),
                    confidence=0.7
                ))

        # æ¨æ–­ç”¨é€”ï¼ˆåŸºäºä¸Šä¸‹æ–‡å…³é”®è¯ï¼‰
        purpose_keywords = {
            "æ¨ç†": "æ¨¡å‹æ¨ç†æœåŠ¡",
            "è®­ç»ƒ": "æ¨¡å‹è®­ç»ƒ",
            "æµ‹è¯•": "æµ‹è¯•ç¯å¢ƒ",
            "å¼€å‘": "å¼€å‘ç¯å¢ƒ",
        }
        for keyword, purpose in purpose_keywords.items():
            if keyword in context:
                properties.append(Property(
                    key="purpose",
                    value=purpose,
                    confidence=0.6
                ))
                break

        return properties

    def infer_project_properties(self, entity: Entity, context: str) -> List[Property]:
        properties = []

        # æ¨æ–­å¯åŠ¨å‘½ä»¤
        command_patterns = [
            r'(python\s+[\w/.]+)',
            r'(\./[\w/.]+\.sh)',
        ]
        for pattern in command_patterns:
            if match := re.search(pattern, context):
                properties.append(Property(
                    key="startup_command",
                    value=match.group(),
                    confidence=0.8
                ))

        # æ¨æ–­ç«¯å£
        port_pattern = r':(\d{4,5})'
        if match := re.search(port_pattern, context):
            properties.append(Property(
                key="port",
                value=match.group(1),
                confidence=0.7
            ))

        return properties
```

### å…³ç³»æ¨æ–­

```python
class RelationInferrer:
    """æ¨æ–­å®ä½“é—´çš„å…³ç³»"""

    def infer_relations(self, entity: Entity, doc: Document,
                       all_entities: List[Entity]) -> List[Relation]:
        relations = []

        context = self.get_context_window(entity, doc)

        # æŸ¥æ‰¾åŒä¸€ä¸Šä¸‹æ–‡ä¸­çš„å…¶ä»–å®ä½“
        for other in all_entities:
            if other.name == entity.name:
                continue

            if other.name in context:
                # åŸºäºä¸Šä¸‹æ–‡å…³é”®è¯æ¨æ–­å…³ç³»ç±»å‹
                relation_type = self.infer_relation_type(
                    entity, other, context
                )

                if relation_type:
                    relations.append(Relation(
                        from_entity=entity.name,
                        to_entity=other.name,
                        type=relation_type,
                        confidence=0.7,
                        source_context=context
                    ))

        return relations

    def infer_relation_type(self, entity1: Entity, entity2: Entity,
                           context: str) -> Optional[str]:
        """åŸºäºä¸Šä¸‹æ–‡å…³é”®è¯æ¨æ–­å…³ç³»ç±»å‹"""

        # éƒ¨ç½²å…³ç³»
        if any(kw in context for kw in ["éƒ¨ç½²", "è¿è¡Œåœ¨", "å¯åŠ¨"]):
            if entity1.type == "server" and entity2.type == "project":
                return "hosts"
            elif entity1.type == "project" and entity2.type == "server":
                return "deployed_on"

        # ä¾èµ–å…³ç³»
        if any(kw in context for kw in ["éœ€è¦", "ä¾èµ–", "require"]):
            return "depends_on"

        # ä½¿ç”¨å…³ç³»
        if any(kw in context for kw in ["ä½¿ç”¨", "use", "based on"]):
            return "uses"

        # å¯åŠ¨å…³ç³»
        if any(kw in context for kw in ["å¯åŠ¨", "start", "./", "python"]):
            if entity1.type == "command" and entity2.type == "project":
                return "starts"

        return None
```

## å¢é‡å­¦ä¹ ï¼ˆIncrementalï¼‰

### æ–‡æ¡£ç›‘å¬

```python
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class DocumentWatcher(FileSystemEventHandler):
    """ç›‘å¬æ–‡æ¡£å˜æ›´"""

    def __init__(self, learning_service):
        self.learning_service = learning_service

    def on_modified(self, event):
        if event.is_directory:
            return

        if self.is_document(event.src_path):
            print(f"æ£€æµ‹åˆ°æ–‡æ¡£ä¿®æ”¹: {event.src_path}")
            self.learning_service.update_document(event.src_path)

    def on_created(self, event):
        if not event.is_directory and self.is_document(event.src_path):
            print(f"æ£€æµ‹åˆ°æ–°æ–‡æ¡£: {event.src_path}")
            self.learning_service.learn_from_document(event.src_path)

    def on_deleted(self, event):
        if not event.is_directory and self.is_document(event.src_path):
            print(f"æ£€æµ‹åˆ°æ–‡æ¡£åˆ é™¤: {event.src_path}")
            self.learning_service.remove_document(event.src_path)

    def is_document(self, path: str) -> bool:
        return path.endswith(('.md', '.txt', '.rst'))

# ä½¿ç”¨
observer = Observer()
observer.schedule(DocumentWatcher(learning_service), path=docs_path, recursive=True)
observer.start()
```

### å¢é‡æ›´æ–°ç­–ç•¥

```python
class IncrementalLearner:
    def update_document(self, doc_path: str):
        """æ–‡æ¡£ä¿®æ”¹åçš„å¢é‡æ›´æ–°"""

        # 1. è¯»å–æ–°å†…å®¹
        new_content = read_file(doc_path)

        # 2. è·å–æ—§çš„çŸ¥è¯†ï¼ˆä»è¯¥æ–‡æ¡£å­¦åˆ°çš„ï¼‰
        old_knowledge = self.knowledge_base.get_by_source(doc_path)

        # 3. æå–æ–°çŸ¥è¯†
        new_entities = self.entity_extractor.extract(new_content)
        new_properties = self.infer_all_properties(new_entities, new_content)
        new_relations = self.infer_all_relations(new_entities, new_content)

        # 4. å¯¹æ¯”å·®å¼‚
        added = set(new_entities) - set(old_knowledge.entities)
        removed = set(old_knowledge.entities) - set(new_entities)

        # 5. æ›´æ–°çŸ¥è¯†åº“
        for entity in added:
            self.knowledge_base.add(entity, source=doc_path)

        for entity in removed:
            # ä¸ç›´æ¥åˆ é™¤ï¼Œè€Œæ˜¯é™ä½ç½®ä¿¡åº¦
            self.knowledge_base.decrease_confidence(
                entity,
                reason=f"ä»æ–‡æ¡£ {doc_path} ä¸­ç§»é™¤"
            )

        # 6. æ£€æµ‹å†²çª
        conflicts = self.detect_conflicts(new_entities)
        if conflicts:
            self.queue_for_confirmation(conflicts)
```

## äº¤äº’å­¦ä¹ ï¼ˆInteractiveï¼‰

### å¯¹è¯ä¸­çš„å­¦ä¹ 

```python
class InteractiveLearner:
    def learn_from_qa(self, question: str, answer: str,
                      user_feedback: Optional[str] = None):
        """ä»é—®ç­”å¯¹è¯ä¸­å­¦ä¹ """

        # 1. æå–é—®é¢˜å’Œç­”æ¡ˆä¸­çš„å®ä½“
        question_entities = self.extract_entities(question)
        answer_entities = self.extract_entities(answer)

        # 2. å»ºç«‹å…³è”ï¼ˆé—®é¢˜ä¸­çš„å®ä½“å’Œç­”æ¡ˆä¸­çš„å®ä½“å¯èƒ½æœ‰å…³ç³»ï¼‰
        for q_entity in question_entities:
            for a_entity in answer_entities:
                if q_entity != a_entity:
                    # æ¨æ–­å…³ç³»
                    relation = self.infer_relation_from_qa(
                        q_entity, a_entity, question, answer
                    )
                    if relation:
                        self.knowledge_base.add_relation(relation)

        # 3. æ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´ç½®ä¿¡åº¦
        if user_feedback:
            self.process_feedback(question_entities + answer_entities, user_feedback)

    def process_feedback(self, entities: List[Entity], feedback: str):
        """å¤„ç†ç”¨æˆ·åé¦ˆ"""

        if feedback in ["æ­£ç¡®", "å¯¹", "yes", "ğŸ‘"]:
            # æå‡ç½®ä¿¡åº¦
            for entity in entities:
                self.knowledge_base.increase_confidence(
                    entity.name,
                    delta=0.1,
                    reason="ç”¨æˆ·ç¡®è®¤æ­£ç¡®"
                )

        elif feedback in ["é”™è¯¯", "ä¸å¯¹", "no", "ğŸ‘"]:
            # é™ä½ç½®ä¿¡åº¦
            for entity in entities:
                self.knowledge_base.decrease_confidence(
                    entity.name,
                    delta=0.2,
                    reason="ç”¨æˆ·æŒ‡å‡ºé”™è¯¯"
                )

        elif "åº”è¯¥æ˜¯" in feedback or "å…¶å®æ˜¯" in feedback:
            # ç”¨æˆ·çº æ­£
            correction = self.extract_correction(feedback)
            self.apply_correction(entities, correction)
```

### ä¸»åŠ¨ç¡®è®¤æœºåˆ¶

```python
class ActiveLearner:
    """ä¸»åŠ¨è¯¢é—®ç”¨æˆ·ä»¥æå‡çŸ¥è¯†è´¨é‡"""

    def should_ask_confirmation(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸»åŠ¨è¯¢é—®"""

        # ç­–ç•¥1ï¼šå¯¹è¯æ¬¡æ•°è¾¾åˆ°é˜ˆå€¼
        if self.conversation_count % 10 == 0:
            return True

        # ç­–ç•¥2ï¼šå‘ç°é«˜é¢‘ä½†ä½ç½®ä¿¡åº¦çš„å®ä½“
        uncertain_entities = self.get_uncertain_high_frequency_entities()
        if len(uncertain_entities) > 3:
            return True

        # ç­–ç•¥3ï¼šæ£€æµ‹åˆ°æœªè§£å†³çš„å†²çª
        unresolved_conflicts = self.get_unresolved_conflicts()
        if len(unresolved_conflicts) > 0:
            return True

        return False

    def generate_confirmation_questions(self) -> List[str]:
        """ç”Ÿæˆç¡®è®¤é—®é¢˜"""
        questions = []

        # 1. é«˜é¢‘ä½ç½®ä¿¡åº¦å®ä½“
        uncertain = self.get_uncertain_high_frequency_entities(limit=3)
        for entity in uncertain:
            questions.append(
                self.generate_entity_question(entity)
            )

        # 2. æœªè§£å†³çš„å†²çª
        conflicts = self.get_unresolved_conflicts(limit=2)
        for conflict in conflicts:
            questions.append(
                self.generate_conflict_question(conflict)
            )

        return questions

    def generate_entity_question(self, entity: Entity) -> str:
        """ä¸ºå®ä½“ç”Ÿæˆç¡®è®¤é—®é¢˜"""

        if entity.type == "server":
            return f"æˆ‘ç»å¸¸çœ‹åˆ°'{entity.name}'ï¼Œå®ƒæ˜¯ä¸€å°æœåŠ¡å™¨å—ï¼Ÿé…ç½®å’Œç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿ"

        elif entity.type == "project":
            return f"'{entity.name}'æ˜¯ä¸€ä¸ªé¡¹ç›®å—ï¼Ÿä¸»è¦åŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ"

        elif entity.type == "environment":
            return f"condaç¯å¢ƒ'{entity.name}'æ˜¯ç”¨æ¥åšä»€ä¹ˆçš„ï¼Ÿ"

        else:
            return f"ä½ èƒ½ç®€å•ä»‹ç»ä¸€ä¸‹'{entity.name}'å—ï¼Ÿ"

    def generate_conflict_question(self, conflict: Conflict) -> str:
        """ä¸ºå†²çªç”Ÿæˆç¡®è®¤é—®é¢˜"""

        if conflict.type == "property_conflict":
            return f"""
            æˆ‘å‘ç°å…³äº'{conflict.entity_name}'çš„ä¿¡æ¯æœ‰çŸ›ç›¾ï¼š
            - {conflict.values[0].source}: {conflict.values[0].value}
            - {conflict.values[1].source}: {conflict.values[1].value}

            å“ªä¸ªæ˜¯å¯¹çš„ï¼Ÿæˆ–è€…å‘ç”Ÿäº†ä»€ä¹ˆå˜åŒ–ï¼Ÿ
            """
```

### ä¸»åŠ¨å­¦ä¹ å¯¹è¯ç¤ºä¾‹

```python
# ç³»ç»Ÿæ£€æµ‹åˆ°åº”è¯¥ä¸»åŠ¨è¯¢é—®
if active_learner.should_ask_confirmation():
    questions = active_learner.generate_confirmation_questions()

    print("\nğŸ’¡ æˆ‘æœ‰å‡ ä¸ªé—®é¢˜æƒ³ç¡®è®¤ï¼ˆå¯ä»¥ç®€å•å›ç­”æˆ–è·³è¿‡ï¼‰ï¼š\n")

    for i, question in enumerate(questions, 1):
        print(f"{i}. {question}")
        user_answer = input("   ä½ çš„å›ç­”: ")

        if user_answer and user_answer != "è·³è¿‡":
            # è§£æç”¨æˆ·å›ç­”å¹¶æ›´æ–°çŸ¥è¯†åº“
            active_learner.process_answer(questions[i-1], user_answer)
```

## çŸ¥è¯†èåˆï¼ˆKnowledge Fusionï¼‰

### åˆå¹¶ç­–ç•¥

```python
class KnowledgeFuser:
    """çŸ¥è¯†èåˆï¼šåˆå¹¶æ¥è‡ªä¸åŒæ¥æºçš„ä¿¡æ¯"""

    def merge_entity(self, existing: Entity, new: Entity) -> Entity:
        """åˆå¹¶åŒä¸€å®ä½“çš„ä¿¡æ¯"""

        # 1. åˆå¹¶åˆ«å
        existing.aliases = list(set(existing.aliases + new.aliases))

        # 2. æ›´æ–°ç½®ä¿¡åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
        existing.confidence = (
            existing.confidence * len(existing.learned_from) +
            new.confidence * len(new.learned_from)
        ) / (len(existing.learned_from) + len(new.learned_from))

        # 3. åˆå¹¶å­¦ä¹ æ¥æº
        existing.learned_from.extend(new.learned_from)

        # 4. æ›´æ–°çŠ¶æ€
        if new.status == "confirmed":
            existing.status = "confirmed"

        return existing

    def merge_property(self, existing: Property, new: Property) -> Property:
        """åˆå¹¶åŒä¸€å±æ€§çš„ä¸åŒå€¼"""

        # å¦‚æœå€¼ç›¸åŒï¼Œæå‡ç½®ä¿¡åº¦
        if existing.value == new.value:
            existing.confidence = min(existing.confidence + 0.1, 1.0)
            return existing

        # å¦‚æœå€¼ä¸åŒï¼Œæ£€æµ‹å†²çª
        else:
            self.conflict_detector.record_conflict(
                Conflict(
                    type="property_conflict",
                    entity_id=existing.entity_id,
                    property_key=existing.key,
                    values=[existing, new]
                )
            )

            # ä¿ç•™ç½®ä¿¡åº¦é«˜çš„
            if new.confidence > existing.confidence:
                return new
            else:
                return existing
```

### ç½®ä¿¡åº¦ä¼ æ’­

```python
class ConfidencePropagation:
    """ç½®ä¿¡åº¦åœ¨å…³ç³»å›¾ä¸­ä¼ æ’­"""

    def propagate(self, entity: Entity):
        """ä¼ æ’­å®ä½“çš„ç½®ä¿¡åº¦åˆ°ç›¸å…³å®ä½“"""

        # 1. è·å–æ‰€æœ‰å…³ç³»
        relations = self.knowledge_base.get_relations(entity.name)

        # 2. ä¼ æ’­åˆ°ç›´æ¥ç›¸å…³çš„å®ä½“
        for relation in relations:
            related_entity = self.knowledge_base.get_entity(relation.to_entity)

            # å¦‚æœå½“å‰å®ä½“é«˜ç½®ä¿¡åº¦ï¼Œç›¸å…³å®ä½“ä¹Ÿå¢åŠ ä¸€ç‚¹ç½®ä¿¡åº¦
            if entity.confidence > 0.8:
                boost = 0.05 * relation.confidence
                related_entity.confidence = min(
                    related_entity.confidence + boost,
                    0.95  # ä¸è¶…è¿‡0.95ï¼Œé¿å…è¿‡åº¦ä¼ æ’­
                )

                self.knowledge_base.update_entity(related_entity)
```

## å†²çªæ£€æµ‹ä¸è§£å†³

### å†²çªæ£€æµ‹

```python
class ConflictDetector:
    """æ£€æµ‹çŸ¥è¯†å†²çª"""

    def detect_all_conflicts(self) -> List[Conflict]:
        conflicts = []

        # 1. å±æ€§å†²çª
        conflicts.extend(self.detect_property_conflicts())

        # 2. å…³ç³»å†²çª
        conflicts.extend(self.detect_relation_conflicts())

        # 3. æ—¶é—´å†²çª
        conflicts.extend(self.detect_temporal_conflicts())

        # 4. é€»è¾‘å†²çª
        conflicts.extend(self.detect_logical_conflicts())

        return conflicts

    def detect_property_conflicts(self) -> List[Conflict]:
        """æ£€æµ‹åŒä¸€å±æ€§çš„ä¸åŒå€¼"""
        conflicts = []

        for entity in self.knowledge_base.all_entities():
            properties = entity.get_properties()

            # æŒ‰keyåˆ†ç»„
            grouped = defaultdict(list)
            for prop in properties:
                grouped[prop.key].append(prop)

            # æ£€æŸ¥æ¯ä¸ªkeyæ˜¯å¦æœ‰å¤šä¸ªä¸åŒçš„å€¼
            for key, props in grouped.items():
                if len(props) > 1:
                    values = [p.value for p in props]
                    if len(set(values)) > 1:  # å€¼ä¸åŒ
                        conflicts.append(Conflict(
                            type="property_conflict",
                            entity_id=entity.id,
                            property_key=key,
                            conflicting_values=props
                        ))

        return conflicts

    def detect_temporal_conflicts(self) -> List[Conflict]:
        """æ£€æµ‹æ—¶é—´çº¿ä¸Šçš„å†²çª"""
        conflicts = []

        # ä¾‹å¦‚ï¼šæ–‡æ¡£Aè¯´"ä½¿ç”¨MySQL"ï¼Œåæ¥æ–‡æ¡£Bè¯´"æ”¹ç”¨PostgreSQL"
        # è¿™å¯èƒ½ä¸æ˜¯å†²çªï¼Œè€Œæ˜¯æ—¶é—´å˜åŒ–

        for entity in self.knowledge_base.all_entities():
            properties_with_time = sorted(
                entity.get_properties(),
                key=lambda p: p.learned_at
            )

            for key in set(p.key for p in properties_with_time):
                key_props = [p for p in properties_with_time if p.key == key]

                if len(key_props) > 1:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æ—¶é—´å˜åŒ–
                    if self.is_temporal_change(key_props):
                        # æ ‡è®°ä¸ºæ—¶é—´å˜åŒ–ï¼Œè€Œéå†²çª
                        entity.add_history_note(
                            f"{key}åœ¨{key_props[0].learned_at}ä»{key_props[0].value}å˜ä¸º{key_props[-1].value}"
                        )
                    else:
                        conflicts.append(Conflict(
                            type="temporal_conflict",
                            entity_id=entity.id,
                            property_key=key,
                            values=key_props
                        ))

        return conflicts
```

### å†²çªè§£å†³

```python
class ConflictResolver:
    """è§£å†³å†²çª"""

    def resolve(self, conflict: Conflict, resolution: str):
        """åº”ç”¨å†²çªè§£å†³æ–¹æ¡ˆ"""

        if conflict.type == "property_conflict":
            self.resolve_property_conflict(conflict, resolution)

        # è®°å½•è§£å†³æ–¹æ¡ˆ
        self.knowledge_base.record_resolution(conflict, resolution)

    def resolve_property_conflict(self, conflict: Conflict, resolution: str):
        """è§£å†³å±æ€§å†²çª"""

        if resolution == "use_latest":
            # ä½¿ç”¨æœ€æ–°çš„å€¼
            latest = max(conflict.values, key=lambda v: v.learned_at)
            self.knowledge_base.set_property(
                entity_id=conflict.entity_id,
                key=conflict.property_key,
                value=latest.value
            )

        elif resolution == "use_most_confident":
            # ä½¿ç”¨ç½®ä¿¡åº¦æœ€é«˜çš„
            best = max(conflict.values, key=lambda v: v.confidence)
            self.knowledge_base.set_property(
                entity_id=conflict.entity_id,
                key=conflict.property_key,
                value=best.value
            )

        elif resolution.startswith("use_value:"):
            # ç”¨æˆ·æŒ‡å®šå€¼
            value = resolution.split(":", 1)[1]
            self.knowledge_base.set_property(
                entity_id=conflict.entity_id,
                key=conflict.property_key,
                value=value,
                confirmed=True
            )

        elif resolution == "both_valid":
            # ä¸¤ä¸ªå€¼éƒ½æœ‰æ•ˆï¼ˆä¾‹å¦‚ï¼šå¤šå®ä¾‹éƒ¨ç½²ï¼‰
            for value in conflict.values:
                self.knowledge_base.add_property(
                    entity_id=conflict.entity_id,
                    key=conflict.property_key,
                    value=value.value,
                    note="å¤šå€¼å¹¶å­˜"
                )
```

## å­¦ä¹ æ•ˆæœè¯„ä¼°

### æŒ‡æ ‡

```python
class LearningMetrics:
    """è¯„ä¼°å­¦ä¹ æ•ˆæœ"""

    def calculate_metrics(self):
        return {
            "total_entities": self.count_entities(),
            "confirmed_entities": self.count_confirmed(),
            "avg_confidence": self.average_confidence(),
            "coverage": self.calculate_coverage(),
            "conflict_rate": self.calculate_conflict_rate(),
        }

    def calculate_coverage(self) -> float:
        """è®¡ç®—çŸ¥è¯†è¦†ç›–ç‡"""
        total_docs = len(self.all_documents())
        docs_with_entities = len(self.documents_with_extracted_entities())
        return docs_with_entities / total_docs

    def calculate_conflict_rate(self) -> float:
        """è®¡ç®—å†²çªç‡"""
        total_entities = self.count_entities()
        conflicted = len(self.get_conflicted_entities())
        return conflicted / total_entities
```

## ä¸‹ä¸€æ­¥

ç»§ç»­é˜…è¯»ï¼š
- [04-APIè®¾è®¡.md](./04-APIè®¾è®¡.md) - APIæ¥å£è§„èŒƒ
- [05-éƒ¨ç½²æŒ‡å—.md](./05-éƒ¨ç½²æŒ‡å—.md) - å®‰è£…å’Œé…ç½®
