# 自演化知识管理系统

## 项目概述

一个**本地部署**的AI记忆助理系统，能够从用户的简洁文档中自动学习和构建结构化知识库。

### 核心理念

> "用户只写简洁的日志，AI自己学会理解上下文"

- 用户文档保持简洁（不改变写作习惯）
- AI通过交互逐步理解用户的"常识"
- 知识库自动维护，持续演化
- 完全本地化，保护隐私

## 问题背景

传统RAG系统的7大问题：

1. **缺乏全局性**：只检索片段，丢失整体结构
2. **隐含信息缺失**：用户的"常识"AI不懂
3. **文档维护困难**：修改后需要重新索引
4. **可能存在矛盾**：不同时期的文档可能冲突
5. **缺少元信息**：时间、可靠性等信息丢失
6. **容易幻觉**：缺少证据推理机制
7. **文档关联性弱**：孤立的片段，缺少关系图

## 解决方案

### 核心机制：自适应学习

```
用户写简洁日志 → AI提取实体 → 推断属性和关系 → 主动确认不确定信息 → 更新知识库
         ↑                                                        ↓
         └────────────────── 持续演化 ──────────────────────────┘
```

### 三层知识架构

```
┌─────────────────────────────────────────┐
│  用户文档层（User Documents）             │
│  - 简洁的日志、笔记                       │
│  - 用户不改变写作习惯                     │
└─────────────────────────────────────────┘
                   ↓ 学习
┌─────────────────────────────────────────┐
│  AI知识库层（AI Knowledge Base）          │
│  - 实体库（服务器、项目、工具）            │
│  - 关系图（依赖、部署、引用）              │
│  - 置信度追踪                            │
└─────────────────────────────────────────┘
                   ↓ 检索增强
┌─────────────────────────────────────────┐
│  检索增强层（RAG with Context）           │
│  - 自动补充背景知识                       │
│  - 引用来源追踪                          │
│  - 不确定性标注                          │
└─────────────────────────────────────────┘
```

## 系统特性

### 1. 渐进式学习

- **被动学习**：从用户文档自动提取知识
- **交互学习**：对话中确认和纠正理解
- **主动学习**：定期询问高频但不确定的实体

### 2. 置信度管理

```json
{
  "entity": "linux81",
  "confidence": 0.92,
  "status": "confirmed",  // draft | inferred | confirmed
  "learned_from": [
    "多次对话确认",
    "文档出现15次"
  ]
}
```

### 3. 冲突检测

自动发现文档中的矛盾信息：
- 同一实体的不同描述
- 时间线上的变化
- 主动询问用户澄清

### 4. 证据追踪

每个回答都标注来源：
```
【事实】linux81是内网服务器 [来源：服务器清单.md]
【推理】可能需要VPN访问 [推理依据：内网服务器通常需要]
【不确定】具体IP地址未在文档中找到
```

## 技术架构

### 部署位置：用户本地

```
用户计算机
├── 工作文档目录/
│   └── 日志/*.md
│
└── AIGenTest/
    └── memory_system/        # 本系统
        ├── core/            # 核心引擎
        ├── api/             # API服务
        ├── cli/             # 命令行工具
        └── .memory_db/      # 知识库存储
```

### 技术栈

**核心依赖：**
- Python 3.9+
- ChromaDB（向量存储）
- SQLite（结构化知识库）
- sentence-transformers（本地embedding）
- FastAPI（API服务）

**可选组件：**
- Neo4j（图数据库，用于复杂关系）
- Flask（Web管理界面）

### 数据流

```
┌─────────┐    ┌──────────┐    ┌──────────┐    ┌────────┐
│ 用户文档 │ →  │ 实体提取 │ →  │ 知识融合 │ →  │ 知识库 │
└─────────┘    └──────────┘    └──────────┘    └────────┘
     ↓                                               ↓
┌─────────┐                                   ┌────────┐
│ 用户提问 │ ← ← ← ← ← ← ← ← ← ← ← ← ← ← ← ← │ RAG检索│
└─────────┘                                   └────────┘
```

## 使用场景

### 场景1：初始化（批量学习）

```bash
# 扫描用户的文档目录
memory-cli bootstrap --docs-path /path/to/your/docs

# 输出：
发现 156 个实体
  - 38 个服务器/环境
  - 52 个项目
  - 66 个工具/命令

需要确认的高频实体（15个）：
  1. linux81 (出现32次) - 推测：服务器
  2. QAMath (出现18次) - 推测：项目
  ...
```

### 场景2：日常问答

```bash
用户: "QAMath怎么启动？"

AI: 【基于文档】
    cd ~/laya/guo/AIGenTest/aiserver/test/QAMath
    python build_index.py  # 先生成索引
    ./start_8b.sh          # 启动服务

    【背景补充】
    - 部署位置：linux81服务器 [置信度: 0.92]
    - 使用模型：Qwen-8B
    - 环境：(qwen) conda环境

    【来源】
    - 日志/2601.md：具体命令
    - AI记忆：linux81和QAMath的关联
```

### 场景3：主动学习

```bash
# 对话10次后
AI: 💡 我有几个问题想确认：

    1. "usa服务器" 在你的日志中出现8次，但我不确定：
       - 具体IP地址是？
       - 是云服务器还是VPS？

    2. "hidream环境" 是做什么用的？

    （可以简单回答，也可以跳过）
```

### 场景4：冲突检测

```bash
AI: ⚠️ 发现潜在冲突：

    QAMath的部署位置：
    - 2024-01日志：linux81
    - 2024-03日志：linux21

    是迁移了吗？还是两台服务器都在运行？

    （回答后我会更新记忆）
```

## 与其他工具的集成

### 集成到NVIDIA聊天应用

```python
# 在你的 aiserver/test/nvidia/app.py 中
from memory_system.api import MemoryClient

memory = MemoryClient()

@app.route('/api/chat', methods=['POST'])
def chat():
    question = request.json['message']

    # 从记忆系统获取背景
    background = memory.get_context(question)

    # 增强的prompt
    enhanced_prompt = f"""
    【背景知识】
    {background}

    【用户问题】
    {question}
    """

    # 调用NVIDIA API...
```

### 命令行工具

```bash
# 查询知识库
memory-cli query "linux81是什么"

# 查看某个实体
memory-cli show linux81

# 手动添加知识
memory-cli add "linux81是公司内网服务器，8核64G"

# 查看学习历史
memory-cli history linux81

# 导出知识图谱
memory-cli export --format graphml
```

## 隐私和安全

### 完全本地化

- ✅ 所有数据存储在本地
- ✅ 不上传任何文档内容
- ✅ LLM调用可选（可用本地模型）

### 数据所有权

- ✅ 知识库文件可读（JSON格式）
- ✅ 随时备份和迁移
- ✅ 可以手动编辑或删除

### 访问控制

```yaml
# config.yaml
docs_paths:
  - /path/to/work/logs
  exclude:
    - "**/private/**"      # 排除私密文档
    - "**/*密码*.md"       # 排除敏感文件
```

## 路线图

### MVP（最小可用版本）- 2周
- [x] 设计文档
- [ ] 实体提取（基于规则）
- [ ] 简单的知识库（JSON存储）
- [ ] 命令行查询工具
- [ ] 基础RAG集成

### V1.0 - 1个月
- [ ] 自动学习机制
- [ ] 置信度管理
- [ ] 冲突检测
- [ ] Web管理界面

### V2.0 - 2个月
- [ ] 主动学习策略
- [ ] 图关系存储
- [ ] 多模态支持（图片、代码）
- [ ] 时间线追踪

### V3.0 - 长期
- [ ] 多用户支持
- [ ] 知识共享机制
- [ ] 本地LLM集成

## 相关文档

- [01-系统架构.md](./01-系统架构.md) - 详细的技术架构
- [02-知识库设计.md](./02-知识库设计.md) - 数据结构设计
- [03-学习机制.md](./03-学习机制.md) - AI如何学习
- [04-API设计.md](./04-API设计.md) - API接口规范
- [05-部署指南.md](./05-部署指南.md) - 安装和配置

## 快速开始

```bash
# 1. 安装依赖
cd memory_system
pip install -r requirements.txt

# 2. 初始化配置
memory-cli init

# 3. 扫描文档
memory-cli bootstrap --docs-path /path/to/your/docs

# 4. 开始使用
memory-cli query "你的问题"
```

## 许可证

MIT License - 完全开源，自由使用

## 贡献

欢迎提Issue和PR！
