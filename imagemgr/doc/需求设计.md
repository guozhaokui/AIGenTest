# 图片文件管理系统 - 需求设计

## 概述
管理大量图片文件，支持去重、多源描述、向量搜索。

## 文件标识
- 使用 **SHA256** 哈希值作为文件唯一标识（取前32位字符）
- 避免文件重复存储

## 描述信息
每个文件可以附带多个描述信息，用于后续的查询：
- vlm1 自动产生的描述
- vlm2 自动产生的描述
- ...
- 人类标注的描述

## 多嵌入设计思路

### 为什么需要多嵌入？
- 不同的 VLM 模型对图片的理解角度不同
- 有的模型擅长物体识别，有的擅长场景理解
- 人工标注可能包含情感、上下文等额外信息
- 多个嵌入增加语义覆盖面，提高搜索召回率

### 一图多嵌入的关系
```
一张图片 (sha256: a1b2c3d4...)
  ├── image.npy     # 图片视觉嵌入（CLIP模型）
  ├── vlm1.npy      # "一只橙色的猫坐在窗台上"（BGE模型）
  ├── vlm2.npy      # "室内场景，阳光，宠物猫"（BGE模型）
  └── human.npy     # "我家的橘猫晒太阳"（BGE模型）
```

### 嵌入模型分组原则
- **不同模型的嵌入不能混合比较**（特征空间不对齐）
- 按嵌入模型分组建立索引：
  - `clip_image` 索引：存放所有图片的视觉嵌入
  - `bge_text` 索引：存放所有文本描述的嵌入
- 查询时选择对应的索引进行搜索

## 目录结构
```
storage/
  xx/yy/zzzzzzzzzzzzzzzzzzzzzzzzzzzz/
  （xx + yy + zzz... 组成完整的 SHA256 前32位）
      image.png              # 原始图片
      description/
          vlm1.txt
          vlm2.txt
          human.txt
          background.txt
          ...
      embedding/
          image.npy          # 图片本身的嵌入向量（CLIP）
          vlm1.npy           # vlm1描述的文本嵌入（BGE）
          vlm2.npy           # vlm2描述的文本嵌入（BGE）
          ...
```

## 索引数据库
使用 **SQLite** 数据库存储索引信息，便于快速查询、筛选和排序。

### 主表：images
| 字段 | 类型 | 说明 |
|------|------|------|
| sha256 | TEXT | 主键，文件哈希（前32位） |
| width | INTEGER | 图片宽度 |
| height | INTEGER | 图片高度 |
| file_size | INTEGER | 文件大小(bytes) |
| format | TEXT | 图片格式 |
| created_at | DATETIME | 入库时间 |
| source | TEXT | 来源标记 |

### 描述表：descriptions
| 字段 | 类型 | 说明 |
|------|------|------|
| image_sha256 | TEXT | 关联的图片哈希 |
| method | TEXT | 描述方法(vlm1/vlm2/human...) |
| has_embedding | INTEGER | 是否已计算嵌入（0/1） |
| created_at | DATETIME | 创建时间 |

> 主键：(image_sha256, method)

### 向量索引表：vector_entries（扁平化存储）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | INTEGER | 自增主键，对应向量索引中的位置 |
| image_sha256 | TEXT | 关联的图片哈希 |
| method | TEXT | 嵌入来源（image/vlm1/vlm2/human...） |
| model | TEXT | 使用的嵌入模型（clip/bge...） |
| index_name | TEXT | 所属索引名称（clip_image/bge_text） |

> 唯一约束：(image_sha256, method)

## 向量索引结构
```
vector_index/
├── clip_image/              # CLIP 图像嵌入索引
│   ├── embeddings.npy       # 所有图片嵌入 (N, 768)
│   └── ids.json             # 位置 -> sha256 映射
│
└── bge_text/                # BGE 文本嵌入索引
    ├── embeddings.npy       # 所有描述嵌入 (M, 768)
    └── ids.json             # 位置 -> (sha256, method) 映射
```

> 注：当数据量增大（>10万）时，可替换为 Faiss 索引以提升性能

## 搜索流程

### 文本搜索流程
```
用户输入: "一只猫在晒太阳"
         ↓
1. 使用 BGE 模型计算查询文本的嵌入向量
         ↓
2. 在 bge_text 索引中搜索，返回 top_k*3 个结果
   （多取一些用于去重）
         ↓
3. 通过 vector_entries 表查询每个结果对应的 (sha256, method)
         ↓
4. 按 sha256 去重，每张图片只保留最高分的匹配
         ↓
5. 返回去重后的 top_k 张图片
   附带信息：匹配分数、匹配到的描述类型(method)
```

### 以图搜图流程
```
用户上传: query.jpg
         ↓
1. 使用 CLIP 模型计算查询图片的嵌入向量
         ↓
2. 在 clip_image 索引中搜索，返回 top_k 个结果
         ↓
3. 通过 vector_entries 表查询每个结果对应的 sha256
         ↓
4. 返回最相似的 top_k 张图片
```

### 搜索结果示例
```json
{
  "results": [
    {
      "sha256": "a1b2c3d4...",
      "score": 0.92,
      "matched_by": "vlm1",
      "matched_text": "一只橙色的猫坐在窗台上晒太阳"
    },
    {
      "sha256": "e5f6g7h8...",
      "score": 0.87,
      "matched_by": "human",
      "matched_text": "我家的猫咪"
    }
  ]
}
```

## 添加图片流程
```
1. 计算图片 SHA256，检查是否已存在
         ↓
2. 创建目录结构 storage/xx/yy/sha256/
         ↓
3. 保存原始图片，提取元信息（尺寸、格式等）
         ↓
4. 写入 images 表
         ↓
5. 使用 CLIP 计算图片嵌入，保存到 embedding/image.npy
         ↓
6. 追加到 clip_image 索引，记录到 vector_entries 表
         ↓
7. （异步）调用 VLM 生成描述 → 保存到 description/
         ↓
8. （异步）使用 BGE 计算描述嵌入 → 保存到 embedding/
         ↓
9. （异步）追加到 bge_text 索引，更新 vector_entries 表
```

## 删除图片流程
```
1. 标记 images 表中 is_deleted = 1（软删除）
   或直接删除记录（硬删除）
         ↓
2. 从 vector_entries 表删除相关记录
         ↓
3. 重建向量索引（或标记为无效，定期清理）
         ↓
4. 删除文件系统中的目录（可选，可延迟执行）
```
