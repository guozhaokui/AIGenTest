# 图片文件管理系统 - 需求设计

## 概述
管理大量图片文件，支持去重、多源描述、向量搜索。

## 文件标识
- 使用 **SHA256** 哈希值作为文件唯一标识（取前32位字符，即128bit）
- 避免文件重复存储
- 碰撞处理：如发生哈希碰撞（概率极低），拒绝入库并记录日志

## 描述信息
每个文件可以附带多个描述信息，用于后续的查询：
- vlm1 自动产生的描述
- vlm2 自动产生的描述
- ...
- 人类标注的描述

## 多嵌入设计思路

### 为什么需要多嵌入？
- 不同的 VLM 模型对图片的理解角度不同
- 有的模型擅长物体识别，有的擅长场景理解
- 人工标注可能包含情感、上下文等额外信息
- 多个嵌入增加语义覆盖面，提高搜索召回率

### 一图多嵌入的关系
```
一张图片 (sha256: a1b2c3d4...)
  ├── image.npy     # 图片视觉嵌入（SigLIP-2 模型，1152维）
  ├── vlm1.npy      # "一只橙色的猫坐在窗台上"（Qwen3-Embedding，2560维）
  ├── vlm2.npy      # "室内场景，阳光，宠物猫"（Qwen3-Embedding，2560维）
  └── human.npy     # "我家的橘猫晒太阳"（Qwen3-Embedding，2560维）
```

### 嵌入模型分组原则
- **不同模型的嵌入不能混合比较**（特征空间不对齐）
- 按嵌入模型分组建立索引：
  - `siglip2_image` 索引：存放所有图片的视觉嵌入（1152维）
  - `qwen3_text` 索引：存放所有文本描述的嵌入（2560维）
- 查询时选择对应的索引进行搜索

## 目录结构
```
storage/
  xx/yy/zzzzzzzzzzzzzzzzzzzzzzzzzzzz/
  （xx + yy + zzz... 组成完整的 SHA256 前32位）
      image.png              # 原始图片
      thumbnail.jpg          # 缩略图（256x256，用于列表预览）
      description/
          vlm1.txt
          vlm2.txt
          human.txt
          background.txt
          ...
      embedding/
          image.npy          # 图片本身的嵌入向量（SigLIP-2，1152维）
          vlm1.npy           # vlm1描述的文本嵌入（Qwen3，2560维）
          vlm2.npy           # vlm2描述的文本嵌入（Qwen3，2560维）
          ...
```

## 索引数据库
使用 **SQLite** 数据库存储索引信息，便于快速查询、筛选和排序。

### 主表：images
| 字段 | 类型 | 说明 |
|------|------|------|
| sha256 | TEXT | 主键，文件哈希（前32位） |
| width | INTEGER | 图片宽度 |
| height | INTEGER | 图片高度 |
| file_size | INTEGER | 文件大小(bytes) |
| format | TEXT | 图片格式 |
| created_at | DATETIME | 入库时间 |
| source | TEXT | 来源标记 |
| status | TEXT | 状态（pending/ready/failed） |
| is_deleted | INTEGER | 软删除标记（0/1） |
| deleted_at | DATETIME | 删除时间 |

### 描述表：descriptions
| 字段 | 类型 | 说明 |
|------|------|------|
| image_sha256 | TEXT | 关联的图片哈希 |
| method | TEXT | 描述方法(vlm1/vlm2/human...) |
| has_embedding | INTEGER | 是否已计算嵌入（0/1） |
| created_at | DATETIME | 创建时间 |

> 主键：(image_sha256, method)

### 向量索引表：vector_entries（扁平化存储）
| 字段 | 类型 | 说明 |
|------|------|------|
| id | INTEGER | 自增主键，对应向量索引中的位置 |
| image_sha256 | TEXT | 关联的图片哈希 |
| method | TEXT | 嵌入来源（image/vlm1/vlm2/human...） |
| model | TEXT | 使用的嵌入模型（clip/bge...） |
| model_version | TEXT | 模型版本号 |
| index_name | TEXT | 所属索引名称（clip_image/bge_text） |

> 唯一约束：(image_sha256, method, model)

### 数据库索引
```sql
CREATE INDEX idx_images_created ON images(created_at);
CREATE INDEX idx_images_source ON images(source);
CREATE INDEX idx_images_status ON images(status);
CREATE INDEX idx_images_deleted ON images(is_deleted);
CREATE INDEX idx_desc_method ON descriptions(method);
CREATE INDEX idx_vector_index ON vector_entries(index_name, id);
CREATE INDEX idx_vector_sha256 ON vector_entries(image_sha256);
```

## 向量索引结构
```
vector_index/
├── siglip2_image_v1/        # SigLIP-2 图像嵌入索引
│   ├── embeddings_0.npy     # 分片存储（每片最多10万条）
│   ├── embeddings_1.npy
│   ├── ids.json             # 位置 -> sha256 映射
│   └── meta.json            # 索引元信息（模型版本、维度等）
│
└── qwen3_text_v1/           # Qwen3 文本嵌入索引
    ├── embeddings_0.npy     # 所有描述嵌入 (M, 2560)
    ├── ids.json             # 位置 -> (sha256, method) 映射
    └── meta.json
```

### 索引说明
- 分片存储：每个 npy 文件最多存储 10 万条向量，便于增量更新
- 版本管理：目录名包含模型版本，模型升级时可并行维护新旧索引
- 当数据量增大（>10万）时，可替换为 Faiss 索引以提升性能
- 定期执行索引重建/压缩任务

## 搜索流程

### 文本搜索流程
```
用户输入: "一只猫在晒太阳"
         ↓
1. 使用 Qwen3-Embedding-4B 模型计算查询文本的嵌入向量
         ↓
2. 在 qwen3_text 索引中搜索，返回 top_k*3 个结果
   （多取一些用于去重）
         ↓
3. 通过 vector_entries 表查询每个结果对应的 (sha256, method)
         ↓
4. 按 sha256 去重，每张图片只保留最高分的匹配
         ↓
5. 返回去重后的 top_k 张图片
   附带信息：匹配分数、匹配到的描述类型(method)
```

### 以图搜图流程
```
用户上传: query.jpg
         ↓
1. 使用 SigLIP-2 模型计算查询图片的嵌入向量
         ↓
2. 在 siglip2_image 索引中搜索，返回 top_k 个结果
         ↓
3. 通过 vector_entries 表查询每个结果对应的 sha256
         ↓
4. 返回最相似的 top_k 张图片
```

### 搜索结果示例
```json
{
  "results": [
    {
      "sha256": "a1b2c3d4...",
      "score": 0.92,
      "matched_by": "vlm1",
      "matched_text": "一只橙色的猫坐在窗台上晒太阳"
    },
    {
      "sha256": "e5f6g7h8...",
      "score": 0.87,
      "matched_by": "human",
      "matched_text": "我家的猫咪"
    }
  ]
}
```

## 添加图片流程
```
1. 计算图片 SHA256，检查是否已存在（碰撞则拒绝）
         ↓
2. 创建目录结构 storage/xx/yy/sha256/
         ↓
3. 保存原始图片，生成缩略图(thumbnail.jpg)
         ↓
4. 提取元信息（尺寸、格式等）
         ↓
5. 写入 images 表，status = 'pending'
         ↓
6. 使用 SigLIP-2 计算图片嵌入，保存到 embedding/image.npy
         ↓
7. 追加到 siglip2_image 索引，记录到 vector_entries 表
         ↓
8. 更新 images 表，status = 'ready'
         ↓
9. （异步）调用 VLM 生成描述 → 保存到 description/
         ↓
10.（异步）使用 Qwen3-Embedding-4B 计算描述嵌入 → 保存到 embedding/
         ↓
11.（异步）追加到 qwen3_text 索引，更新 vector_entries 表
```

### 失败处理
- 步骤 1-8 任一环节失败，标记 status = 'failed'，记录错误日志
- 定期清理 status = 'failed' 的残留文件
- 异步任务（9-11）失败可重试，不影响图片主流程

## 删除图片流程
```
1. 标记 images 表中 is_deleted = 1（软删除）
   或直接删除记录（硬删除）
         ↓
2. 从 vector_entries 表删除相关记录
         ↓
3. 重建向量索引（或标记为无效，定期清理）
         ↓
4. 删除文件系统中的目录（可选，可延迟执行）
```

## 嵌入服务管理

### 设计目标
- 支持多种嵌入模型（CLIP、BGE、OpenAI 等）
- 支持多种部署方式（第三方 API、自建服务）
- 统一接口，业务代码无需关心具体实现
- 支持故障转移和负载均衡

### 服务配置表：embedding_services
| 字段 | 类型 | 说明 |
|------|------|------|
| id | TEXT | 服务标识（如 clip_local, bge_api） |
| model_type | TEXT | 模型类型（clip/bge/openai...） |
| model_name | TEXT | 具体模型名（如 ViT-B-32, bge-large-zh） |
| model_version | TEXT | 模型版本号 |
| service_type | TEXT | 服务类型（local/api） |
| endpoint | TEXT | API 地址（自建服务或第三方） |
| api_key | TEXT | API 密钥（加密存储，可为空） |
| dimension | INTEGER | 嵌入维度（如 768, 1024） |
| priority | INTEGER | 优先级（数字越小优先级越高） |
| is_enabled | INTEGER | 是否启用（0/1） |
| rate_limit | INTEGER | 请求频率限制（次/分钟，0表示无限制） |
| timeout | INTEGER | 超时时间（秒） |
| created_at | DATETIME | 创建时间 |

### 配置文件示例
```yaml
# config/embedding_services.yaml

services:
  # === SigLIP2 图片嵌入（本地服务，1.14B 最强版本） ===
  siglip2_local:
    model_name: siglip2-so400m-patch16-512
    model_version: "1.0"
    service_type: local
    endpoint: http://localhost:6010/embed/image
    dimension: 1152
    priority: 1
    timeout: 30

  # === Qwen3-4B 文本嵌入（复用 Z-Image-Turbo 的 text_encoder） ===
  qwen3_embed_local:
    model_name: Qwen3-4B
    model_version: "1.0"
    service_type: local
    endpoint: http://localhost:6011/embed/text
    dimension: 2560
    priority: 1
    timeout: 10
    # 注：使用倒数第二层 hidden_states[-2] 作为嵌入
```

### 索引与模型的绑定关系
```
向量索引目录                    绑定的模型                      维度
─────────────────────────────────────────────────────────────────
siglip2_image_v1/              siglip2-so400m-patch16-512      1152
qwen3_text_v1/                 Qwen3-4B v1.0                   2560
```

查询时：
1. 确定要搜索的索引（如 `qwen3_text_v1`）
2. 从 `meta.json` 读取该索引绑定的模型信息
3. 调用 `EmbeddingManager.get_service("Qwen3-Embedding-4B", "1.0")` 获取服务
4. 该模型有两个服务提供者，按优先级尝试（本地优先，失败用 API）

### 统一接口设计
```python
class EmbeddingService:
    """统一嵌入服务接口"""
    
    def embed_image(self, image_path: str) -> np.ndarray:
        """计算图片嵌入向量"""
        pass
    
    def embed_text(self, text: str) -> np.ndarray:
        """计算文本嵌入向量"""
        pass
    
    def embed_texts_batch(self, texts: list[str]) -> np.ndarray:
        """批量计算文本嵌入"""
        pass

class EmbeddingManager:
    """嵌入服务管理器"""
    
    def __init__(self, config_path: str):
        self.services = self._load_services(config_path)
    
    def get_service(self, model_name: str, model_version: str) -> EmbeddingService:
        """
        根据模型名称和版本获取服务
        同一模型可能有多个服务提供者（本地/API），按优先级故障转移
        """
        pass
    
    def get_service_for_index(self, index_name: str) -> EmbeddingService:
        """
        根据索引名称获取对应的嵌入服务
        索引 -> 模型映射关系在 vector_index/{index_name}/meta.json 中
        """
        pass
```

### 核心原则
- **索引与模型绑定**：每个向量索引绑定特定的 (model_name, model_version)
- **查询必须匹配**：查询时必须使用与索引相同的模型计算查询向量
- **同模型可多服务**：同一模型可配置多个服务提供者（本地 + API），用于故障转移

### 服务调用流程
```
请求嵌入计算（需指定 model_name + model_version）
     ↓
1. EmbeddingManager 查找该模型的所有可用服务
     ↓
2. 按优先级排序，过滤掉 is_enabled=0 的服务
     ↓
3. 依次尝试调用：
   ├── 检查频率限制
   ├── 发送请求（带超时）
   ├── 成功 → 返回结果
   └── 失败 → 记录日志，尝试下一个同模型服务
     ↓
4. 所有服务都失败 → 抛出异常，上层处理
```

### 健康检查
```
定时任务（每分钟）：
  对每个 is_enabled=1 的服务发送心跳请求
  ├── 响应正常 → 保持启用
  └── 连续失败3次 → 自动禁用，发送告警
```

### 自建服务接口规范
为了统一管理，自建服务需要遵循以下 API 规范：

```
POST /embed/image
Content-Type: multipart/form-data
Body: image file

Response:
{
  "embedding": [0.1, 0.2, ...],  // 嵌入向量
  "dimension": 512,
  "model": "ViT-B-32"
}

---

POST /embed/text
Content-Type: application/json
Body: {"text": "一只猫"}  或  {"texts": ["文本1", "文本2"]}

Response:
{
  "embeddings": [[0.1, 0.2, ...], ...],
  "dimension": 1024,
  "model": "bge-large-zh-v1.5"
}

---

GET /health
Response: {"status": "ok", "model": "...", "version": "..."}
```
