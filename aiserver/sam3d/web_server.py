"""
SAM 3D Body Web æœåŠ¡
æä¾›å¯è§†åŒ–ç•Œé¢ï¼Œæ”¯æŒä¸Šä¼ å›¾ç‰‡è¿›è¡Œ3Däººä½“é‡å»º
"""

import os
import sys
import json
import time
import numpy as np
from pathlib import Path

# æ·»åŠ  sam-3d-body åˆ° PYTHONPATH
SAM3D_PATH = Path(__file__).parent.parent / "third_party" / "sam-3d-body"
if str(SAM3D_PATH) not in sys.path:
    sys.path.insert(0, str(SAM3D_PATH))

import gradio as gr
from sam3d_body_demo import SAM3DBodyEstimator


# å…¨å±€å˜é‡
estimator = None
model_loaded = False


def load_model():
    """åŠ è½½æ¨¡å‹ï¼ˆå¸¦é¢„çƒ­ï¼‰"""
    global estimator, model_loaded
    
    if model_loaded:
        return "æ¨¡å‹å·²åŠ è½½"
    
    import time
    
    print("=" * 60)
    print("ğŸ”„ [1/3] æ­£åœ¨åˆå§‹åŒ– SAM3DBodyEstimator...")
    t0 = time.time()
    
    estimator = SAM3DBodyEstimator(
        use_detector=False,  # ç®€åŒ–ï¼Œä¸ç”¨æ£€æµ‹å™¨
        use_fov_estimator=False
    )
    print(f"âœ… [1/3] åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time() - t0:.2f}ç§’")
    
    # é¢„çƒ­
    print("ğŸ”„ [2/3] é¢„çƒ­ä¸­ï¼ˆé¦–æ¬¡æ¨ç†ï¼Œç¼–è¯‘CUDA kernelï¼‰...")
    t0 = time.time()
    dummy = np.zeros((512, 512, 3), dtype=np.uint8)
    _ = estimator.process_image(dummy)
    print(f"âœ… [2/3] é¢„çƒ­å®Œæˆï¼Œè€—æ—¶: {time.time() - t0:.2f}ç§’")
    
    print("ğŸ”„ [3/3] å¯åŠ¨ Gradio ç•Œé¢...")
    model_loaded = True
    print("=" * 60)
    print("ğŸ‰ æ¨¡å‹åŠ è½½å®Œæˆï¼æœåŠ¡å³å°†å¯åŠ¨...")
    print("=" * 60)
    return "æ¨¡å‹åŠ è½½å®Œæˆ"


def process_image(image):
    """å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡"""
    global estimator, model_loaded
    
    if not model_loaded:
        load_model()
    
    if image is None:
        return None, None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡"
    
    start_time = time.time()
    print("\n" + "-" * 40)
    print(f"ğŸ“· æ”¶åˆ°æ–°å›¾ç‰‡ï¼Œå°ºå¯¸: {image.shape}")
    
    try:
        # è½¬æ¢å›¾åƒæ ¼å¼ (Gradioè¿”å›RGBï¼Œéœ€è¦è½¬BGR)
        import cv2
        img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        
        # æ¨ç†
        print("ğŸ”„ æ­£åœ¨æ¨ç†...")
        t0 = time.time()
        outputs = estimator.process_image(img_bgr)
        inference_time = time.time() - t0
        print(f"âœ… æ¨ç†å®Œæˆï¼Œè€—æ—¶: {inference_time:.3f}ç§’ï¼Œæ£€æµ‹åˆ° {len(outputs)} ä¸ªäººä½“")
        
        # æå–æ•°æ®
        print("ğŸ”„ æå–ç»“æ„åŒ–æ•°æ®...")
        result = estimator.process_and_extract(img_bgr)
        print("âœ… æ•°æ®æå–å®Œæˆ")
        
        # å¯è§†åŒ–
        print("ğŸ”„ ç”Ÿæˆå¯è§†åŒ–å›¾åƒ...")
        t0 = time.time()
        vis_img = estimator.visualize(img_bgr, outputs)
        vis_img_rgb = cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)
        print(f"âœ… å¯è§†åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time() - t0:.3f}ç§’")
        
        total_time = time.time() - start_time
        print(f"ğŸ‰ å¤„ç†å®Œæˆï¼æ€»è€—æ—¶: {total_time:.3f}ç§’")
        print("-" * 40)
        
        # ç”Ÿæˆç»“æœæ‘˜è¦
        num_persons = result.get("num_persons", 0)
        
        summary_lines = [
            f"## ğŸ“Š æ£€æµ‹ç»“æœ",
            f"",
            f"**æ£€æµ‹åˆ°äººæ•°**: {num_persons}",
            f"**æ¨ç†è€—æ—¶**: {inference_time:.3f} ç§’",
            f"**æ€»å¤„ç†è€—æ—¶**: {total_time:.3f} ç§’",
            f"",
        ]
        
        if num_persons > 0:
            for i, person in enumerate(result.get("persons", [])):
                summary_lines.extend([
                    f"### ğŸ‘¤ äººç‰© {i+1}",
                    f"",
                ])
                
                # é¡¶ç‚¹ä¿¡æ¯
                if "pred_vertices" in person:
                    v = person["pred_vertices"]
                    summary_lines.append(f"- **3Dç½‘æ ¼é¡¶ç‚¹**: {v.get('num_vertices', 'N/A')} ä¸ª")
                
                # å…³é”®ç‚¹ä¿¡æ¯
                if "pred_keypoints_3d" in person:
                    kp = person["pred_keypoints_3d"]
                    summary_lines.append(f"- **3Då…³é”®ç‚¹**: {kp.get('shape', ['N/A'])[0]} ä¸ª")
                
                if "pred_keypoints_2d" in person:
                    kp = person["pred_keypoints_2d"]
                    summary_lines.append(f"- **2Då…³é”®ç‚¹**: {kp.get('shape', ['N/A'])[0]} ä¸ª")
                
                # æ—‹è½¬ä¿¡æ¯
                if "pred_global_rots" in person:
                    rot = person["pred_global_rots"]
                    summary_lines.append(f"- **å…³èŠ‚æ—‹è½¬**: {rot.get('num_joints', 'N/A')} ä¸ªå…³èŠ‚ (3Ã—3çŸ©é˜µ)")
                
                # å‚æ•°ä¿¡æ¯
                if "body_pose_params" in person:
                    bp = person["body_pose_params"]
                    summary_lines.append(f"- **èº«ä½“å§¿æ€å‚æ•°**: {bp.get('shape', ['N/A'])[0]} ç»´")
                
                if "shape_params" in person:
                    sp = person["shape_params"]
                    summary_lines.append(f"- **ä½“å‹å‚æ•°**: {sp.get('shape', ['N/A'])[0]} ç»´")
                
                if "focal_length" in person:
                    summary_lines.append(f"- **ç„¦è·**: {person['focal_length']:.2f}")
                
                summary_lines.append("")
        
        summary = "\n".join(summary_lines)
        
        # æ ¼å¼åŒ–JSONï¼ˆç²¾ç®€ç‰ˆï¼‰
        json_result = {
            "image_info": result.get("image_info"),
            "num_persons": num_persons,
            "inference_time_sec": round(inference_time, 3),
        }
        
        if num_persons > 0:
            json_result["persons"] = []
            for person in result.get("persons", []):
                p = {
                    "person_id": person.get("person_id"),
                    "num_vertices": person.get("pred_vertices", {}).get("num_vertices"),
                    "num_keypoints_3d": person.get("pred_keypoints_3d", {}).get("shape", [0])[0],
                    "num_joints": person.get("pred_global_rots", {}).get("num_joints"),
                    "focal_length": person.get("focal_length"),
                    "bbox": person.get("bbox"),
                }
                json_result["persons"].append(p)
        
        json_str = json.dumps(json_result, indent=2, ensure_ascii=False)
        
        return vis_img_rgb, summary, json_str
        
    except Exception as e:
        import traceback
        error_msg = f"å¤„ç†å‡ºé”™: {str(e)}\n{traceback.format_exc()}"
        return None, error_msg, None


def download_full_result(image):
    """ä¸‹è½½å®Œæ•´JSONç»“æœ"""
    global estimator, model_loaded
    
    if not model_loaded or image is None:
        return None
    
    import cv2
    img_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    result = estimator.process_and_extract(img_bgr)
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    output_path = "/tmp/sam3d_result.json"
    
    def convert_to_serializable(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.float32, np.float64)):
            return float(obj)
        elif isinstance(obj, (np.int32, np.int64)):
            return int(obj)
        elif isinstance(obj, dict):
            return {k: convert_to_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [convert_to_serializable(v) for v in obj]
        return obj
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(convert_to_serializable(result), f, indent=2, ensure_ascii=False)
    
    return output_path


# åˆ›å»ºç•Œé¢
def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(
        title="SAM 3D Body - 3Däººä½“é‡å»º",
        theme=gr.themes.Soft(
            primary_hue="blue",
            secondary_hue="slate",
        ),
        css="""
        .main-title {
            text-align: center;
            margin-bottom: 20px;
        }
        .result-box {
            min-height: 400px;
        }
        """
    ) as demo:
        
        gr.HTML("""
        <div class="main-title">
            <h1>ğŸ§ SAM 3D Body</h1>
            <p>åŸºäº DINOv3 çš„å•å›¾3Däººä½“ç½‘æ ¼é‡å»º</p>
        </div>
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¤ ä¸Šä¼ å›¾ç‰‡")
                input_image = gr.Image(
                    label="è¾“å…¥å›¾ç‰‡",
                    type="numpy",
                    height=400
                )
                
                with gr.Row():
                    submit_btn = gr.Button("ğŸš€ å¼€å§‹å¤„ç†", variant="primary", size="lg")
                    clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…é™¤", size="lg")
                
                gr.Markdown("""
                **æç¤º**ï¼š
                - é¦–æ¬¡å¤„ç†éœ€è¦åŠ è½½æ¨¡å‹ï¼ˆçº¦10ç§’ï¼‰
                - åç»­å¤„ç†æ¯å¼ å›¾çº¦0.8ç§’
                - å»ºè®®ä¸Šä¼ åŒ…å«å®Œæ•´äººä½“çš„å›¾ç‰‡
                """)
                
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ–¼ï¸ å¯è§†åŒ–ç»“æœ")
                output_image = gr.Image(
                    label="3Dç½‘æ ¼å åŠ ",
                    height=400
                )
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“‹ æ£€æµ‹æ‘˜è¦")
                output_summary = gr.Markdown(
                    value="ç­‰å¾…å¤„ç†...",
                    elem_classes=["result-box"]
                )
            
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“„ JSONç»“æœ (ç²¾ç®€)")
                output_json = gr.Code(
                    label="JSON",
                    language="json",
                    lines=15
                )
                download_btn = gr.Button("ğŸ“¥ ä¸‹è½½å®Œæ•´JSON")
                download_file = gr.File(label="ä¸‹è½½æ–‡ä»¶", visible=False)
        
        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=process_image,
            inputs=[input_image],
            outputs=[output_image, output_summary, output_json]
        )
        
        clear_btn.click(
            fn=lambda: (None, None, "ç­‰å¾…å¤„ç†...", None),
            inputs=[],
            outputs=[input_image, output_image, output_summary, output_json]
        )
        
        download_btn.click(
            fn=download_full_result,
            inputs=[input_image],
            outputs=[download_file]
        )
        
        # ç¤ºä¾‹å›¾ç‰‡
        gr.Examples(
            examples=[
                ["/data1/guo/AIGenTest/aiserver/embedding/test/å¥³æ€§è£¸ä½“é›•å¡‘çš„é»‘ç™½ç…§ç‰‡.jpeg"],
            ],
            inputs=[input_image],
            label="ğŸ“¸ ç¤ºä¾‹å›¾ç‰‡"
        )
    
    return demo


def main():
    """å¯åŠ¨æœåŠ¡"""
    import argparse
    
    parser = argparse.ArgumentParser(description="SAM 3D Body WebæœåŠ¡")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡åœ°å€")
    parser.add_argument("--port", type=int, default=7860, help="æœåŠ¡ç«¯å£")
    parser.add_argument("--share", action="store_true", help="åˆ›å»ºå…¬å…±é“¾æ¥")
    parser.add_argument("--preload", action="store_true", help="å¯åŠ¨æ—¶é¢„åŠ è½½æ¨¡å‹")
    args = parser.parse_args()
    
    print("=" * 60)
    print("SAM 3D Body Web æœåŠ¡")
    print("=" * 60)
    
    # é¢„åŠ è½½æ¨¡å‹
    if args.preload:
        load_model()
    
    # åˆ›å»ºç•Œé¢
    demo = create_interface()
    
    print(f"\nğŸŒ æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
    print("=" * 60)
    
    # å¯åŠ¨æœåŠ¡
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
        show_error=True
    )


if __name__ == "__main__":
    main()

