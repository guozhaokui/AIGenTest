#!/usr/bin/env python3
"""æµ‹è¯•é¦–é€‰æ¨¡å‹çš„å„ç§èƒ½åŠ›"""

import os
import json
import time
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
root_dir = Path(__file__).resolve().parent.parent.parent.parent
env_path = root_dir / '.env'
load_dotenv(dotenv_path=env_path)

NVIDIA_API_KEY = os.getenv('NVIDIA_API_KEY')

client = OpenAI(
    base_url="https://integrate.api.nvidia.com/v1",
    api_key=NVIDIA_API_KEY
)

# é¦–é€‰æ¨¡å‹
TOP_MODELS = [
    ("z-ai/glm4.7", "GLM-4.7"),
    ("minimaxai/minimax-m2.1", "MiniMax M2.1"),
    ("moonshotai/kimi-k2-thinking", "Kimi K2 Thinking"),
    ("deepseek-ai/deepseek-r1-0528", "DeepSeek R1"),
    ("deepseek-ai/deepseek-v3.2", "DeepSeek V3.2"),
]

# å·¥å…·å®šä¹‰
tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"}
                },
                "required": ["city"]
            }
        }
    }
]


def test_basic_chat(model_id, model_name):
    """æµ‹è¯•åŸºæœ¬èŠå¤©"""
    print(f"\n  [åŸºæœ¬èŠå¤©]", end=" ")
    try:
        start = time.time()
        completion = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"}],
            max_tokens=100,
            temperature=0.7
        )
        elapsed = time.time() - start
        content = completion.choices[0].message.content[:50]
        print(f"âœ… ({elapsed:.1f}s) {content}...")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def test_reasoning(model_id, model_name):
    """æµ‹è¯•æ¨ç†èƒ½åŠ›ï¼ˆæ€è€ƒè¿‡ç¨‹ï¼‰"""
    print(f"\n  [æ¨ç†/æ€è€ƒ]", end=" ")
    try:
        start = time.time()
        completion = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "7 * 8 = ?"}],
            max_tokens=500,
            temperature=0.1
        )
        elapsed = time.time() - start
        message = completion.choices[0].message

        # æ£€æŸ¥æ˜¯å¦æœ‰æ€è€ƒå†…å®¹
        reasoning = None
        if hasattr(message, 'model_extra') and message.model_extra:
            reasoning = message.model_extra.get('reasoning_content')

        if reasoning:
            print(f"âœ… æœ‰æ€è€ƒè¿‡ç¨‹ ({elapsed:.1f}s)")
            print(f"      æ€è€ƒ: {reasoning[:60]}...")
            print(f"      ç­”æ¡ˆ: {message.content[:40]}")
        else:
            print(f"âš ï¸ æ— æ€è€ƒè¿‡ç¨‹ ({elapsed:.1f}s)")
            print(f"      ç­”æ¡ˆ: {message.content[:60]}")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def test_tool_calling(model_id, model_name):
    """æµ‹è¯•å·¥å…·è°ƒç”¨"""
    print(f"\n  [å·¥å…·è°ƒç”¨]", end=" ")
    try:
        start = time.time()
        completion = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "åŒ—äº¬å¤©æ°”å¦‚ä½•ï¼Ÿ"}],
            tools=tools,
            tool_choice="auto",
            max_tokens=200,
            temperature=0.1
        )
        elapsed = time.time() - start
        message = completion.choices[0].message

        if message.tool_calls:
            tc = message.tool_calls[0]
            print(f"âœ… æ”¯æŒ ({elapsed:.1f}s)")
            print(f"      å‡½æ•°: {tc.function.name}")
            print(f"      å‚æ•°: {tc.function.arguments}")
        else:
            print(f"âš ï¸ æœªè°ƒç”¨å·¥å…· ({elapsed:.1f}s)")
            if message.content:
                print(f"      å›å¤: {message.content[:50]}...")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def test_streaming(model_id, model_name):
    """æµ‹è¯•æµå¼è¾“å‡º"""
    print(f"\n  [æµå¼è¾“å‡º]", end=" ")
    try:
        start = time.time()
        stream = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "æ•°åˆ°5"}],
            max_tokens=50,
            stream=True
        )

        chunks = 0
        content = ""
        reasoning = ""

        for chunk in stream:
            chunks += 1
            if chunk.choices and len(chunk.choices) > 0:
                delta = chunk.choices[0].delta
                if delta.content:
                    content += delta.content
                if hasattr(delta, 'model_extra') and delta.model_extra:
                    r = delta.model_extra.get('reasoning_content')
                    if r:
                        reasoning += r

        elapsed = time.time() - start

        if reasoning:
            print(f"âœ… ({elapsed:.1f}s, {chunks} chunks, æœ‰æ€è€ƒæµ)")
        else:
            print(f"âœ… ({elapsed:.1f}s, {chunks} chunks)")
        print(f"      å†…å®¹: {content[:50]}...")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def test_chinese(model_id, model_name):
    """æµ‹è¯•ä¸­æ–‡èƒ½åŠ›"""
    print(f"\n  [ä¸­æ–‡èƒ½åŠ›]", end=" ")
    try:
        start = time.time()
        completion = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "ç”¨æˆè¯­å½¢å®¹æ˜¥å¤©"}],
            max_tokens=100,
            temperature=0.7
        )
        elapsed = time.time() - start
        content = completion.choices[0].message.content
        print(f"âœ… ({elapsed:.1f}s) {content[:50]}...")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def test_code(model_id, model_name):
    """æµ‹è¯•ä»£ç èƒ½åŠ›"""
    print(f"\n  [ä»£ç èƒ½åŠ›]", end=" ")
    try:
        start = time.time()
        completion = client.chat.completions.create(
            model=model_id,
            messages=[{"role": "user", "content": "å†™ä¸€ä¸ªPythonå†’æ³¡æ’åºï¼Œåªè¦ä»£ç "}],
            max_tokens=300,
            temperature=0.1
        )
        elapsed = time.time() - start
        content = completion.choices[0].message.content
        has_code = "def" in content or "for" in content
        print(f"âœ… ({elapsed:.1f}s) {'æœ‰ä»£ç ' if has_code else 'æ— ä»£ç '}")
        print(f"      {content[:60].replace(chr(10), ' ')}...")
        return True
    except Exception as e:
        print(f"âŒ {str(e)[:50]}")
        return False


def main():
    print("=" * 70)
    print("NVIDIA NIM é¦–é€‰æ¨¡å‹èƒ½åŠ›æµ‹è¯•")
    print("=" * 70)

    results = {}

    for model_id, model_name in TOP_MODELS:
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ {model_name} ({model_id})")
        print("=" * 70)

        results[model_name] = {
            "basic": test_basic_chat(model_id, model_name),
            "reasoning": test_reasoning(model_id, model_name),
            "tool": test_tool_calling(model_id, model_name),
            "stream": test_streaming(model_id, model_name),
            "chinese": test_chinese(model_id, model_name),
            "code": test_code(model_id, model_name),
        }

        time.sleep(1)  # é¿å…é¢‘ç‡é™åˆ¶

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    print(f"\n{'æ¨¡å‹':<20} {'åŸºæœ¬':<6} {'æ¨ç†':<6} {'å·¥å…·':<6} {'æµå¼':<6} {'ä¸­æ–‡':<6} {'ä»£ç ':<6}")
    print("-" * 70)

    for model_name, tests in results.items():
        row = f"{model_name:<20}"
        for test_name in ["basic", "reasoning", "tool", "stream", "chinese", "code"]:
            status = "âœ…" if tests.get(test_name) else "âŒ"
            row += f" {status:<6}"
        print(row)

    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    main()
