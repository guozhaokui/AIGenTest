#!/bin/bash
#
# Qwen3-VL VLM æœåŠ¡å¯åŠ¨è„šæœ¬
# ä½¿ç”¨ conda ç¯å¢ƒ qwen
#

# é…ç½®
HOST="${HOST:-0.0.0.0}"
PORT="${PORT:-6050}"
GPU="${GPU:-1}"
MODEL_PATH="${MODEL_PATH:-/data1/MLLM/qwen2.5vl/Qwen/Qwen/Qwen3-VL-8B-Instruct}"

# åˆ‡æ¢åˆ°è„šæœ¬ç›®å½•
cd "$(dirname "$0")"

# æ¿€æ´» conda ç¯å¢ƒ
echo "ğŸ”„ æ¿€æ´» conda ç¯å¢ƒ: qwen"
source ~/anaconda3/etc/profile.d/conda.sh 2>/dev/null || source ~/miniconda3/etc/profile.d/conda.sh 2>/dev/null || source /opt/conda/etc/profile.d/conda.sh 2>/dev/null
conda activate qwen

if [ $? -ne 0 ]; then
    echo "âŒ æ— æ³•æ¿€æ´» conda ç¯å¢ƒ qwen"
    echo "è¯·ç¡®ä¿å·²åˆ›å»º qwen ç¯å¢ƒ: conda create -n qwen python=3.10"
    exit 1
fi

echo "âœ… å·²æ¿€æ´» conda ç¯å¢ƒ: $(conda info --envs | grep '*' | awk '{print $1}')"

# å¯åŠ¨æœåŠ¡
exec python vlm_service.py \
    --host "$HOST" \
    --port "$PORT" \
    --gpu "$GPU" \
    --model-path "$MODEL_PATH" \
    "$@"

